{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import nengo\n",
    "import nengolib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy as sp\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import pytry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we just read the raw data file.  We drop any rows that have N/A data in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"pinsoro-2017-06-20-145454904791-small.csv\", low_memory=False)\n",
    "\n",
    "x = np.array(data.iloc[:,11:195]).astype(float) #array of data for purple child (points in space for each frame)\n",
    "labs = np.array(data.iloc[:,218]).astype(str) #array of labels (purple child annotations, engagement)\n",
    "a = []\n",
    "for i in range(x.shape[1]):\n",
    "    y = pd.Series(x[:,i])\n",
    "    z = y.interpolate(limit_direction='both')\n",
    "    a.append(z)\n",
    "a = pd.DataFrame(a)\n",
    "a = a.dropna()\n",
    "a = np.array(a).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a helper function to take a window of that data, extract it out, and resample it to a given dt using interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pattern(start, end, target_dt): #function to extract consecutive frames with the same label \n",
    "    pattern = np.array(a[start:end,:]).astype(float)\n",
    "    frames = np.array(data.iloc[start:end,9]).astype(int)\n",
    "\n",
    "    good_indices = frames != -1\n",
    "    frames = frames[good_indices]\n",
    "    pattern = pattern[good_indices]\n",
    "\n",
    "    fps = 30.0\n",
    "    t_sample = (frames - frames[0])/fps\n",
    "\n",
    "    t = np.arange(int(t_sample[-1]/target_dt))*target_dt\n",
    "\n",
    "    result = []\n",
    "    for i in range(pattern.shape[1]):       \n",
    "        p = np.interp(t, t_sample, pattern[:,i])\n",
    "        result.append(p)\n",
    "    result = np.array(result).T\n",
    "\n",
    "    return t, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we find the slices of data that correspond to different labelled events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=[]\n",
    "start.append(0)\n",
    "end=[]\n",
    "label = []\n",
    "for i in range(1, (len(labs)-1)):\n",
    "    if labs[i]!=labs[i-1]:\n",
    "        start.append(i)\n",
    "    if labs[i]!=labs[i+1]:\n",
    "        end.append(i)\n",
    "        label.append(labs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then extract all that data out.  Notice that we're extracting it out with a dt of 1/30s, since that's about what the data is stored at.  This means we're not generating huge datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_noplay=[]\n",
    "p_noplay=[]\n",
    "t_goal=[]\n",
    "p_goal=[]\n",
    "t_aim=[]\n",
    "p_aim=[]\n",
    "\n",
    "target_dt = 1.0/30\n",
    "\n",
    "for i in range(1,(len(start)-1)):\n",
    "    if label[i]==('noplay'):\n",
    "        ti, pi = extract_pattern(start[i], end[i], target_dt=target_dt)\n",
    "        t_noplay.append(ti)\n",
    "        p_noplay.append(pi)\n",
    "    if label[i]==('goaloriented'):\n",
    "        ti, pi = extract_pattern(start[i], end[i], target_dt=target_dt)\n",
    "        t_goal.append(ti)\n",
    "        p_goal.append(pi)\n",
    "    if label[i]==('aimless'):\n",
    "        ti, pi = extract_pattern(start[i], end[i], target_dt=target_dt)\n",
    "        t_aim.append(ti)\n",
    "        p_aim.append(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we collect all that data together and define training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "############ randomly split data 80/20 into training and testing sets ############ \n",
    "random.shuffle(p_goal)\n",
    "goal_train = p_goal[:(int(len(p_goal)*0.8))] \n",
    "goal_test = p_goal[(int(len(p_goal)*0.8)):]\n",
    "\n",
    "random.shuffle(p_noplay)\n",
    "noplay_train = p_noplay[:(int(len(p_noplay)*0.8))]\n",
    "noplay_test = p_noplay[(int(len(p_noplay)*0.8)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the PCA (just on the training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = np.vstack(goal_train+noplay_train)\n",
    "pca_model = PCA(n_components=2).fit(train_all)\n",
    "\n",
    "goal_train_pca = np.vstack([pca_model.transform(p) for p in goal_train])\n",
    "noplay_train_pca = np.vstack([pca_model.transform(p) for p in noplay_train])\n",
    "goal_test_pca = np.vstack([pca_model.transform(p) for p in goal_test])\n",
    "noplay_test_pca = np.vstack([pca_model.transform(p) for p in noplay_test])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For speed reasons, we can control how much of the training and testing data to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_train = 20   # number of seconds to train on for each class\n",
    "T_test = 20    # number of seconds to test on for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_frames = int(T_train*30)\n",
    "training = np.vstack([goal_train_pca[:N_frames], noplay_train_pca[:N_frames]])\n",
    "assert len(training) == N_frames*2\n",
    "\n",
    "N_frames = int(T_test*30)\n",
    "testing = np.vstack([goal_test_pca[:N_frames], noplay_test_pca[:N_frames]])\n",
    "assert len(testing) == N_frames*2\n",
    "\n",
    "plt.plot(np.arange(len(training))/30.0,training)\n",
    "plt.axvline(T_train, ls=':')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed the training data into the network and record what information would be fed into the pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 2\n",
    "\n",
    "theta = 0.5\n",
    "net = nengo.Network(seed=seed)\n",
    "with net:\n",
    "    process = nengo.processes.WhiteSignal(period=100., high=3.0, y0=0)\n",
    "    rw = []\n",
    "    for i in range(D):\n",
    "        rw.append(nengolib.networks.RollingWindow(theta=theta, n_neurons=3000, \n",
    "                                                  process=process, \n",
    "                                                  neuron_type=nengo.LIFRate()))\n",
    "        \n",
    "    \n",
    "    node_pool = nengo.Node(None, size_in=rw[0].state.size_out*D)\n",
    "\n",
    "    start = 0\n",
    "    for r in rw:\n",
    "        nengo.Connection(r.state, node_pool[start:start+r.state.size_out])\n",
    "        start += r.state.size_out\n",
    "        \n",
    "        \n",
    "    \n",
    "    stim = nengo.Node(nengo.processes.PresentInput(training, presentation_time=1.0/30))\n",
    "    assert stim.size_out == D\n",
    "    for i in range(D):\n",
    "        nengo.Connection(stim[i], rw[i].input, synapse=None)\n",
    "\n",
    "    p_node_pool = nengo.Probe(node_pool)\n",
    "        \n",
    "        \n",
    "sim = nengo.Simulator(net)\n",
    "with sim:\n",
    "    sim.run(T_train*2)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's actually make that pool of neurons, and then compute its activity for the values that the rolling windows will feed into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pool_model = nengo.Network()\n",
    "with pool_model:\n",
    "    pool = nengo.Ensemble(n_neurons=3000, dimensions=node_pool.size_out,\n",
    "                          neuron_type=nengo.LIFRate(), seed=1)\n",
    "pool_sim = nengo.Simulator(pool_model)\n",
    "    \n",
    "import nengo.utils.ensemble\n",
    "\n",
    "_, a = nengo.utils.ensemble.tuning_curves(pool, pool_sim, inputs=sim.data[p_node_pool])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's compute a decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int(T_train*1000)\n",
    "target = np.hstack([np.ones(N), -np.ones(N)]).reshape(-1, 1)\n",
    "dec, info = nengo.solvers.LstsqL2(reg=0.1)(a, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does that decoder do?   We could compute rmse, but instead of that let's do classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.dot(a, dec)\n",
    "classify1 = np.isclose(v[:N], 1, atol=0.5)\n",
    "classify2 = np.isclose(v[N:], -1, atol=0.5)\n",
    "classify = np.append(classify1, classify2)\n",
    "score = np.mean(classify)\n",
    "\n",
    "plt.plot(sim.trange(), classify)\n",
    "plt.plot(sim.trange(), v)\n",
    "plt.axvline(T_train, ls=':')\n",
    "plt.title('training classification accuracy: %1.2f%%' % (score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run it on the test set.  We combine the rolling window, the pool, and the decoder into one model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "D = 2\n",
    "\n",
    "theta = 0.5\n",
    "test_net = nengo.Network(seed=seed)\n",
    "with test_net:\n",
    "    process = nengo.processes.WhiteSignal(period=100., high=3.0, y0=0)\n",
    "    rw = []\n",
    "    for i in range(D):\n",
    "        rw.append(nengolib.networks.RollingWindow(theta=theta, n_neurons=3000, \n",
    "                                                  process=process, \n",
    "                                                  neuron_type=nengo.LIFRate()))\n",
    "        \n",
    "    \n",
    "    pool = nengo.Ensemble(n_neurons=3000, dimensions=node_pool.size_out,\n",
    "                          neuron_type=nengo.LIFRate(), seed=1)\n",
    "\n",
    "    start = 0\n",
    "    for r in rw:\n",
    "        nengo.Connection(r.state, pool[start:start+r.state.size_out])\n",
    "        start += r.state.size_out\n",
    "        \n",
    "        \n",
    "    \n",
    "    stim = nengo.Node(nengo.processes.PresentInput(training, presentation_time=1.0/30))\n",
    "    assert stim.size_out == D\n",
    "    for i in range(D):\n",
    "        nengo.Connection(stim[i], rw[i].input, synapse=None)\n",
    "\n",
    "    p_stim = nengo.Probe(stim)\n",
    "    \n",
    "    result = nengo.Node(None, size_in=1)\n",
    "    nengo.Connection(pool.neurons, result, transform=dec.T, synapse=None)\n",
    "    \n",
    "    p_result = nengo.Probe(result)\n",
    "    \n",
    "    \n",
    "test_sim = nengo.Simulator(test_net)\n",
    "test_sim.run(T_test*2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int(T_test*1000)\n",
    "\n",
    "v = test_sim.data[p_result]\n",
    "classify1 = np.isclose(v[:N], 1, atol=0.5)\n",
    "classify2 = np.isclose(v[N:], -1, atol=0.5)\n",
    "classify = np.append(classify1, classify2)\n",
    "score = np.mean(classify)\n",
    "\n",
    "plt.plot(sim.trange(), classify)\n",
    "plt.plot(test_sim.trange(), v)\n",
    "plt.axvline(T_test, ls=':')\n",
    "plt.title('testing classification accuracy: %1.2f%%' % (score*100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we test on the aimless patterns where the output should be around 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(p_aim)\n",
    "\n",
    "aimless_patterns1 = {}\n",
    "aimless_patterns2 = {}\n",
    "i=0\n",
    "for ap in p_aim:\n",
    "    aimless_patterns1[i] = pca_model.transform(ap)[:,0]\n",
    "    aimless_patterns2[i] = pca_model.transform(ap)[:,1]\n",
    "    i+=1\n",
    "\n",
    "N_frames = int(T_test*30)\n",
    "\n",
    "test_aim1 = np.array(aimless_patterns1[0])\n",
    "for ap in range(1,(len(aimless_patterns1))):\n",
    "    test_aim1 = np.hstack([test_aim1,aimless_patterns1[ap]])\n",
    "test_aim1 = test_aim1[:N_frames]\n",
    "\n",
    "test_aim2 = np.array(aimless_patterns2[0])\n",
    "for ap in range(1,(len(aimless_patterns2))):\n",
    "    test_aim2 = np.hstack([test_aim2,aimless_patterns2[ap]])\n",
    "test_aim2 = test_aim2[:N_frames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aim = np.vstack([test_aim1[:N_frames], test_aim2[:N_frames]]).T\n",
    "assert len(test_aim) == N_frames\n",
    "\n",
    "\n",
    "plt.plot(np.arange(len(test_aim))/30.0,test_aim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 2\n",
    "\n",
    "theta = 0.5\n",
    "aim_test_net = nengo.Network(seed=seed)\n",
    "with aim_test_net:\n",
    "    process = nengo.processes.WhiteSignal(period=100., high=3.0, y0=0)\n",
    "    rw = []\n",
    "    for i in range(D):\n",
    "        rw.append(nengolib.networks.RollingWindow(theta=theta, n_neurons=3000, \n",
    "                                                  process=process, \n",
    "                                                  neuron_type=nengo.LIFRate()))\n",
    "        \n",
    "    \n",
    "    pool = nengo.Ensemble(n_neurons=3000, dimensions=node_pool.size_out,\n",
    "                          neuron_type=nengo.LIFRate(), seed=1)\n",
    "\n",
    "    start = 0\n",
    "    for r in rw:\n",
    "        nengo.Connection(r.state, pool[start:start+r.state.size_out])\n",
    "        start += r.state.size_out\n",
    "        \n",
    "        \n",
    "    \n",
    "    stim = nengo.Node(nengo.processes.PresentInput(test_aim, presentation_time=1.0/30))\n",
    "    assert stim.size_out == D\n",
    "    for i in range(D):\n",
    "        nengo.Connection(stim[i], rw[i].input, synapse=None)\n",
    "\n",
    "    p_stim = nengo.Probe(stim)\n",
    "    \n",
    "    result = nengo.Node(None, size_in=1)\n",
    "    nengo.Connection(pool.neurons, result, transform=dec.T, synapse=None)\n",
    "    \n",
    "    p_result = nengo.Probe(result)\n",
    "    \n",
    "    \n",
    "aim_test_sim = nengo.Simulator(aim_test_net)\n",
    "aim_test_sim.run(T_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = aim_test_sim.data[p_result]\n",
    "classify = np.isclose(v, 0, atol=0.5)\n",
    "score = np.mean(classify)\n",
    "\n",
    "plt.plot(aim_test_sim.trange(), classify)\n",
    "plt.plot(aim_test_sim.trange(), v)\n",
    "plt.title('testing classification accuracy: %1.2f%%' % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
