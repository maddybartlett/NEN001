{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import nengo\n",
    "import nengolib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp"
   ]
  }, 
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "data = pd.read_csv(\"pinsoro-2017-06-01-102743523980-small.csv\", low_memory=False)\n",
    "\n",
    "dt = 0.001\n",
    "\n",
    "def extract_pattern(start, end):\n",
    "    pattern = np.array(data.iloc[start:end,11:195]).astype(float)\n",
    "    frames = np.array(data.iloc[start:end,9]).astype(int)\n",
    "\n",
    "    good_indices = frames != -1\n",
    "    frames = frames[good_indices]\n",
    "    pattern = pattern[good_indices]\n",
    "\n",
    "    fps = 30.0\n",
    "    t_sample = (frames - frames[0])/fps\n",
    "\n",
    "    t = np.arange(int(t_sample[-1]/dt))*dt\n",
    "    \n",
    "    result = []\n",
    "    for i in range(pattern.shape[1]):\n",
    "        p = np.interp(t, t_sample, pattern[:,i])\n",
    "        #bad_indexes = np.isnan(p)\n",
    "        #good_indexes = np.logical_not(bad_indexes)\n",
    "        #good_pattern = p[good_indexes]\n",
    "        #interpolated = np.interp(bad_indexes.nonzero(), good_indexes.nonzero(), p[:,1])\n",
    "        #p[bad_indexes] = interpolated\n",
    "        result.append(p)\n",
    "    result = np.array(result).T\n",
    "    \n",
    "    return t, result\n",
    "\n",
    "\n",
    "t1, result1 = extract_pattern(2977, 3379)\n",
    "t2, result2 = extract_pattern(3702, 4104)\n",
    "\n",
    "#np.savetxt('result.csv', result1, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'interp1d'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-7a19864c5d32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_component\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_component\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-7a19864c5d32>\u001b[0m in \u001b[0;36mextract_component\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnb_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_component\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpca_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cumulative explained variance: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpca_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\pca.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \"\"\"\n\u001b[1;32m--> 329\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\pca.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,\n\u001b[1;32m--> 370\u001b[1;33m                         copy=self.copy)\n\u001b[0m\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;31m# Handle n_components==None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    431\u001b[0m                                       force_all_finite)\n\u001b[0;32m    432\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'interp1d'"
     ]
    }
   ],
   "source": [
    "nb_components=1\n",
    "def extract_component(data):\n",
    "    pca_model=PCA(n_components=nb_components).fit(data)\n",
    "    p = pca_model.transform(data)\n",
    "    print(\"Cumulative explained variance: %s\" % pca_model.explained_variance_ratio_.cumsum())\n",
    "    \n",
    "    return p\n",
    "\n",
    "p1 = extract_component(result1)\n",
    "p2 = extract_component(result2)\n",
    "\n",
    "plt.plot(t1, p1)\n",
    "plt.plot(t2, p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Pattern 1 is goal oriented play. \n",
    "Pattern 2 is no-play. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a network that represents a rolling window in time (Aaron's \"delay network\"). The process determines what sort of pattern the network will be optimized for -- here we just go with white noise of a maximum of 3Hz.  theta determines how big the rolling window is -- here we use 0.5 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 0.402\n",
    "\n",
    "net = nengo.Network()\n",
    "with net:\n",
    "    process = nengo.processes.WhiteSignal(period=100., high=3.0, y0=0)\n",
    "    rw = nengolib.networks.RollingWindow(theta=theta, n_neurons=3000, process=process, neuron_type=nengo.LIFRate(tau_rc=0.02, tau_ref=0.002, amplitude=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create the training data for decoding out of the rolling window. Our patterns are larger than the rolling window, so to create our training data we will take our patterns, shift them, and cut them down to the right size. In order to then give that to nengo, we also need to project from the window's space to the internal representation space (using the inv_basis).\n",
    "\n",
    "The target array is the desired output value for each of the slices of the pattern in eval_points. We'll use 1 for pattern1 and -1 for pattern2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_window = int(theta/dt)\n",
    "s_pattern = min(len(p1), len(p2))\n",
    "\n",
    "t_window = np.linspace(0, 1, s_window)\n",
    "inv_basis = rw.inverse_basis(t_window)\n",
    "    \n",
    "eval_points=[]\n",
    "target = []\n",
    "for i in range(s_pattern):\n",
    "    eval_points.append(np.dot(inv_basis, np.roll(p1, i)[:s_window]))\n",
    "    target.append([1])\n",
    "    eval_points.append(np.dot(inv_basis, np.roll(p2, i)[:s_window]))\n",
    "    target.append([-1])\n",
    "    \n",
    "eval_points = np.array(eval_points)\n",
    "print(eval_points.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a connection optimized to do this decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with net:\n",
    "    result = nengo.Node(None, size_in=1)\n",
    "    nengo.Connection(rw.state, result,\n",
    "                     eval_points=eval_points, scale_eval_points=True,\n",
    "                     function=target, synapse=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try feeding in those two patterns and see what the response is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_all = np.hstack([p1, p2])\n",
    "\n",
    "model = nengo.Network()\n",
    "model.networks.append(net)\n",
    "with model:    \n",
    "    stim = nengo.Node(nengo.processes.PresentInput(p_all, presentation_time=0.015))\n",
    "    nengo.Connection(stim, rw.input, synapse=None)\n",
    "    \n",
    "    p_result = nengo.Probe(result)\n",
    "    p_stim = nengo.Probe(stim)\n",
    "sim = nengo.Simulator(model)\n",
    "sim.run(30)\n",
    "\n",
    "plt.plot(sim.trange(), sim.data[p_stim], label='input')\n",
    "plt.plot(sim.trange(), sim.data[p_result], label='output')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
