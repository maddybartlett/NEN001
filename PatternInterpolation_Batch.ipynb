{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import nengolib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy as sp\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from itertools import islice\n",
    "import nengo\n",
    "\n",
    "import pytry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we just read the raw data file.  We drop any rows that have N/A data in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"multidata.csv\", low_memory=False)\n",
    "\n",
    "x = np.array(data.iloc[:,11:195]).astype(float) #array of data for purple child (points in space for each frame)\n",
    "labs = np.array(data.iloc[:,443]).astype(str) #array of labels (purple child annotations, engagement) 218/443\n",
    "a = []\n",
    "for i in range(x.shape[1]):\n",
    "    y = pd.Series(x[:,i])\n",
    "    if i == 180:               # add these three lines\n",
    "        y[y>0]-=np.pi*2   # add these three lines\n",
    "        y += np.pi            # add these three lines\n",
    "    z = y.interpolate(limit_direction='both')\n",
    "    a.append(z)\n",
    "a = pd.DataFrame(a)\n",
    "a = a.dropna()\n",
    "a = np.array(a).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dims=2 \n",
    "seed=1\n",
    "\n",
    "dt = 0.001\n",
    "target_dt = 1.0/30\n",
    "D = n_dims # param.n_dims\n",
    "classify_score = {}\n",
    "accuracy = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a helper function to take a window of that data, extract it out, and resample it to a given dt using interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pattern(start, end, target_dt): #function to extract consecutive frames with the same label \n",
    "    pattern = np.array(a[start:end,:]).astype(float)\n",
    "    frames = np.array(data.iloc[start:end,9]).astype(int)\n",
    "    timestamp = np.array(data.iloc[start:end,0]).astype(str)\n",
    "\n",
    "    good_indices = frames != -1\n",
    "    frames = frames[good_indices]\n",
    "    pattern = pattern[good_indices]\n",
    "\n",
    "    fps = 30.0\n",
    "    t_sample = (frames - frames[0])/fps\n",
    "\n",
    "    t = np.arange(int(t_sample[-1]/target_dt))*target_dt\n",
    "\n",
    "    result = []\n",
    "    for i in range(pattern.shape[1]):       \n",
    "        p = np.interp(t, t_sample, pattern[:,i])\n",
    "        result.append(p)\n",
    "    result = np.array(result).T\n",
    "\n",
    "    return timestamp, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we find the slices of data that correspond to different labelled events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=[]\n",
    "start.append(0)\n",
    "end=[]\n",
    "label = []\n",
    "for i in range(1, (len(labs)-1)):\n",
    "    if labs[i]!=labs[i-1]:\n",
    "        start.append(i)\n",
    "    if labs[i]!=labs[i+1]:\n",
    "        end.append(i)\n",
    "        label.append(labs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then extract all that data out.  Notice that we're extracting it out with a dt of 1/30s, since that's about what the data is stored at.  This means we're not generating huge datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty pattern\n"
     ]
    }
   ],
   "source": [
    "t_noplay=[]\n",
    "p_noplay=[]\n",
    "t_goal=[]\n",
    "p_goal=[]\n",
    "t_aim=[]\n",
    "p_aim=[]\n",
    "\n",
    "for i in range(1,(len(start)-1)):\n",
    "    try:\n",
    "        if label[i]==('noplay'):\n",
    "            ts, pi = extract_pattern(start[i], end[i], target_dt=target_dt)\n",
    "            t_noplay.append(ts)\n",
    "            p_noplay.append(pi)\n",
    "        if label[i]==('goaloriented'):\n",
    "            ts, pi = extract_pattern(start[i], end[i], target_dt=target_dt)\n",
    "            t_goal.append(ts)\n",
    "            p_goal.append(pi)\n",
    "        if label[i]==('aimless'):\n",
    "            ts, pi = extract_pattern(start[i], end[i], target_dt=target_dt)\n",
    "            t_aim.append(ts)\n",
    "            p_aim.append(pi)\n",
    "    except IndexError:\n",
    "        print('empty pattern')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we collect all that data together and define training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "goal = []\n",
    "noplay = []\n",
    "aim = []\n",
    "for entry in t_goal:\n",
    "    goal.append([t_goal[i],p_goal[i]])\n",
    "    i = i+1\n",
    "i=0\n",
    "for entry in t_noplay:\n",
    "    noplay.append([t_noplay[i],p_noplay[i]])\n",
    "    i = i+1\n",
    "i=0\n",
    "for entry in t_aim:\n",
    "    aim.append([t_aim[i],p_aim[i]])\n",
    "    i = i+1\n",
    "\n",
    "p_goal2 = random.sample(goal, len(goal))\n",
    "p_noplay2 = random.sample(noplay, len(noplay))\n",
    "p_aim2 = random.sample(aim, len(aim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ randomly split data 80/20 into training and testing sets ############ \n",
    "goal_train_ts = np.array(p_goal2[:(int(len(p_goal2)*0.8))]) \n",
    "goal_test_ts = np.array(p_goal2[(int(len(p_goal2)*0.8)):]) \n",
    "goal_train_list=list(goal_train_ts[:,1])\n",
    "goal_test_list=list(goal_test_ts[:,1])\n",
    "goal_train_time=list(goal_train_ts[:,0])\n",
    "goal_test_time=list(goal_test_ts[:,0])\n",
    "\n",
    "noplay_train_ts = np.array(p_noplay2[:(int(len(p_noplay2)*0.8))]) \n",
    "noplay_test_ts = np.array(p_noplay2[(int(len(p_noplay2)*0.8)):]) \n",
    "noplay_train_list=list(noplay_train_ts[:,1])\n",
    "noplay_test_list=list(noplay_test_ts[:,1])\n",
    "noplay_train_time=list(noplay_train_ts[:,0])\n",
    "noplay_test_time=list(noplay_test_ts[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbartlett2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for p in noplay_train_list:\n",
    "    if p.size > 0:\n",
    "        pass\n",
    "    else:\n",
    "        noplay_train_list.remove(p)\n",
    "        \n",
    "for p in noplay_test_list:\n",
    "    if p.size >0:\n",
    "        pass\n",
    "    else:\n",
    "        noplay_test_list.remove(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the PCA (just on the training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = np.vstack(goal_train_list+noplay_train_list)\n",
    "pca_model = PCA(n_components=D).fit(train_all)\n",
    "\n",
    "train_time_all = np.hstack(goal_train_time+noplay_train_time)\n",
    "test_time_all = np.hstack(goal_test_time+noplay_test_time)\n",
    "\n",
    "goal_train_pca = np.vstack([pca_model.transform(p) for p in goal_train_list])\n",
    "noplay_train_pca = np.vstack([pca_model.transform(p) for p in noplay_train_list])\n",
    "goal_test_pca = np.vstack([pca_model.transform(p) for p in goal_test_list])\n",
    "noplay_test_pca = np.vstack([pca_model.transform(p) for p in noplay_test_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For speed reasons, we can control how much of the training and testing data to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184464\n",
      "13673\n"
     ]
    }
   ],
   "source": [
    "print(len(goal_train_pca))\n",
    "print(len(noplay_test_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training Pattern for each pattern type:  2000\n",
      "Length of Testing Pattern for each pattern type:  100\n"
     ]
    }
   ],
   "source": [
    "len_train = 2000 #int(len(noplay_train_pca)/30)\n",
    "T_train = len_train #param.len_train   # number of seconds to train on for each class\n",
    "T_test = 100 #len of noplay test 67    # number of seconds to test on for each class\n",
    "\n",
    "print('Length of Training Pattern for each pattern type: ', len_train)\n",
    "print('Length of Testing Pattern for each pattern type: ', T_test)\n",
    "\n",
    "goal_train_time2 = [item for sublist in goal_train_time for item in sublist]\n",
    "noplay_train_time2 = [item for sublist in noplay_train_time for item in sublist]\n",
    "\n",
    "goal_test_time2 = [item for sublist in goal_test_time for item in sublist]\n",
    "noplay_test_time2 = [item for sublist in noplay_test_time for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a8b187b5ae06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgoal_train_pca\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mN_frames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoplay_train_pca\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mN_frames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_timestamps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgoal_train_time2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mN_frames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoplay_train_time2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mN_frames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mN_frames\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mN_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT_test\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_frames = int(T_train*30)\n",
    "training = np.vstack([goal_train_pca[:N_frames], noplay_train_pca[:N_frames]])\n",
    "train_timestamps = np.hstack([goal_train_time2[:N_frames], noplay_train_time2[:N_frames]])\n",
    "assert len(training) == N_frames*2\n",
    "\n",
    "N_frames = int(T_test*30)\n",
    "testing = np.vstack([goal_test_pca[:N_frames], noplay_test_pca[:N_frames]])\n",
    "test_timestamps = np.hstack([goal_test_time2[:N_frames], noplay_test_time2[:N_frames]])\n",
    "assert len(testing) == N_frames*2\n",
    "\n",
    "plt.plot(training)\n",
    "plt.axvline(int(len(training)/2), ls=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed the training data into the network and record what information would be fed into the pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ TRAINING WITH 80% ############ \n",
    "num_epochs = 1 \n",
    "batch_size = int(T_train*30)\n",
    "batch = 0\n",
    "theta = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    training = np.vstack([goal_train_pca[batch:int(batch+batch_size)], noplay_train_pca[batch:int(batch+batch_size)]])\n",
    "    batch += batch_size\n",
    "    \n",
    "    net = nengo.Network(seed=seed)#param.seed)\n",
    "    with net:\n",
    "        rw = []\n",
    "        for i in range(D):\n",
    "            process = nengo.processes.PresentInput(np.hstack([goal_train_pca[:,i], noplay_train_pca[:,i]]), \n",
    "                                                       presentation_time=1.0/30)\n",
    "            rw.append(nengolib.networks.RollingWindow(theta=theta, n_neurons=3000, \n",
    "                                                      process=process, \n",
    "                                                      neuron_type=nengo.Direct()))\n",
    "\n",
    "\n",
    "        node_pool = nengo.Node(None, size_in=rw[0].state.size_out*D)\n",
    "\n",
    "        start = 0\n",
    "        for r in rw:\n",
    "            nengo.Connection(r.state, node_pool[start:start+r.state.size_out])\n",
    "            start += r.state.size_out\n",
    "\n",
    "\n",
    "\n",
    "        stim = nengo.Node(nengo.processes.PresentInput(training, presentation_time=1.0/30))\n",
    "        assert stim.size_out == D\n",
    "        for i in range(D):\n",
    "            nengo.Connection(stim[i], rw[i].input, synapse=None)\n",
    "\n",
    "        p_node_pool = nengo.Probe(node_pool, sample_every = 0.1)\n",
    "\n",
    "\n",
    "    sim = nengo.Simulator(net)\n",
    "    with sim:\n",
    "        sim.run(T_train*2)  \n",
    "                \n",
    "        \n",
    "    pool_model = nengo.Network()\n",
    "    with pool_model:\n",
    "        pool = nengo.Ensemble(n_neurons=3000, dimensions=node_pool.size_out,\n",
    "                              neuron_type=nengo.LIFRate(), seed=seed)\n",
    "    pool_sim = nengo.Simulator(pool_model)\n",
    "\n",
    "    import nengo.utils.ensemble\n",
    "\n",
    "    _, a = nengo.utils.ensemble.tuning_curves(pool, pool_sim, inputs=sim.data[p_node_pool])\n",
    "                                       \n",
    "    if epoch == 0:\n",
    "        a_goal = a[:(int(len(a)/2))]\n",
    "        a_noplay = a[(int(len(a)/2)):]\n",
    "    else:\n",
    "        a_goal = np.concatenate((a_goal, a[:(int(len(a)/2))]))\n",
    "        a_noplay = np.concatenate((a_noplay, a[(int(len(a)/2)):]))\n",
    "    \n",
    "a_out = np.vstack([a_goal, a_noplay])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's compute a decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int((len(a_out))/2) #int(T_train*1000)\n",
    "target = np.hstack([np.ones(N), -np.ones(N)]).reshape(-1, 1)\n",
    "dec, info = nengo.solvers.LstsqL2(reg=0.1)(a_out, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does that decoder do?   We could compute rmse, but instead of that let's do classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.dot(a_out, dec)\n",
    "classify1 = np.isclose(v[:N], 1, atol=0.5)\n",
    "classify2 = np.isclose(v[N:], -1, atol=0.5)\n",
    "classify = np.append(classify1, classify2)\n",
    "score_train = np.mean(classify)\n",
    "\n",
    "classify_score[0]=score_train\n",
    "\n",
    "accuracy = dict(islice(enumerate(v), None, None, 100)) \n",
    "accuracy_train={}\n",
    "for i in range(len(accuracy)):\n",
    "    accuracy_train[i]=accuracy[i*100]\n",
    "\n",
    "for j in range(len(accuracy_train)):      \n",
    "    key_j = 'accuracy_train{}'.format(\"%04d\" % j)  \n",
    "    accuracy_train[key_j] = accuracy_train.pop(j)      \n",
    "\n",
    "plt.plot(classify)\n",
    "plt.plot(v)\n",
    "plt.axvline(int(len(classify)/2), ls=':')\n",
    "plt.title('training classification accuracy: %1.2f%%' % (score_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''data = pd.DataFrame(output_train)\n",
    "data = pd.DataFrame(data.iloc[0::2])\n",
    "data = data.reset_index(drop=True)\n",
    "data'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(15, 4))\n",
    "ax1.hist(v[:N], label='goal training')\n",
    "ax2.hist(v[N:], label='noplay training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run it on the test set.  We combine the rolling window, the pool, and the decoder into one model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ TESTING WITH 20% ############ \n",
    "test_net = nengo.Network(seed=seed)#param.seed)\n",
    "with test_net:\n",
    "    rw = []\n",
    "    for i in range(D):\n",
    "        process = nengo.processes.PresentInput(np.hstack([goal_train_pca[:,i], noplay_train_pca[:,i]]), \n",
    "                                                   presentation_time=1.0/30)\n",
    "        rw.append(nengolib.networks.RollingWindow(theta=theta, n_neurons=3000, \n",
    "                                                  process=process, \n",
    "                                                  neuron_type=nengo.Direct()))\n",
    "\n",
    "\n",
    "    pool = nengo.Ensemble(n_neurons=3000, dimensions=node_pool.size_out,\n",
    "                          neuron_type=nengo.LIFRate(), seed=seed)\n",
    "\n",
    "    start = 0\n",
    "    for r in rw:\n",
    "        nengo.Connection(r.state, pool[start:start+r.state.size_out])\n",
    "        start += r.state.size_out\n",
    "\n",
    "\n",
    "\n",
    "    stim = nengo.Node(nengo.processes.PresentInput(testing, presentation_time=1.0/30))\n",
    "    assert stim.size_out == D\n",
    "    for i in range(D):\n",
    "        nengo.Connection(stim[i], rw[i].input, synapse=None)\n",
    "\n",
    "    p_stim = nengo.Probe(stim)\n",
    "\n",
    "    result = nengo.Node(None, size_in=1)\n",
    "    nengo.Connection(pool.neurons, result, transform=dec.T, synapse=None)\n",
    "\n",
    "    p_test_result_sample = nengo.Probe(result, sample_every = 0.1)\n",
    "\n",
    "\n",
    "test_sim = nengo.Simulator(test_net)\n",
    "test_sim.run(T_test*2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int(T_test*10)\n",
    "\n",
    "v = test_sim.data[p_test_result_sample]\n",
    "classify1 = np.isclose(v[:N], 1, atol=0.5)\n",
    "classify2 = np.isclose(v[N:], -1, atol=0.5)\n",
    "classify = np.append(classify1, classify2)\n",
    "score_test = np.mean(classify)\n",
    "\n",
    "classify_score[1]=score_test\n",
    "    \n",
    "plt.plot(classify)\n",
    "plt.plot(v)\n",
    "plt.axvline(int(len(classify)/2), ls=':')\n",
    "plt.title('testing classification accuracy: %1.2f%%' % (score_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(15, 4))\n",
    "ax1.hist(v[:N], label='goal testing')\n",
    "ax2.hist(v[N:], label='noplay testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test on the aimless patterns where the output should be around 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ TESTING WITH AIMLESS PATTERNS ############ \n",
    "#p_aim = random.sample(p_aim, len(p_aim))\n",
    "\n",
    "#aim_train_pca = np.vstack([pca_model.transform(p) for p in p_aim])\n",
    "\n",
    "#A_len = int(len(aim_train_pca)/30) #Testing on full aimless data\n",
    "#print(A_len)\n",
    "\n",
    "#N_frames = T_test*30\n",
    "\n",
    "#test_aim = np.vstack([aim_train_pca[:N_frames]])\n",
    "#assert len(test_aim) == N_frames\n",
    "\n",
    "aim_list=list(p_aim2[:,1])\n",
    "aim_time=list(p_aim2[:,0])\n",
    "aim_time_all = np.hstack(aim_time)\n",
    "\n",
    "aim_train_pca = np.vstack([pca_model.transform(p) for p in aim_list])\n",
    "aim_time2 = [item for sublist in aim_time_all for item in sublist]\n",
    "\n",
    "N_frames = T_test*30\n",
    "test_aim = np.vstack([aim_train_pca[:N_frames]])\n",
    "assert len(test_aim) == N_frames\n",
    "\n",
    "aim_timestamps = np.hstack([aim_time2[:N_frames]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_aim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aim_test_net = nengo.Network(seed=seed)#param.seed)\n",
    "with aim_test_net:\n",
    "    rw = []\n",
    "    for i in range(D):\n",
    "        process = nengo.processes.PresentInput(np.hstack([goal_train_pca[:,i], noplay_train_pca[:,i]]), \n",
    "                                                   presentation_time=1.0/30)\n",
    "        rw.append(nengolib.networks.RollingWindow(theta=theta, n_neurons=3000, \n",
    "                                                  process=process, \n",
    "                                                  neuron_type=nengo.Direct()))\n",
    "\n",
    "\n",
    "    pool = nengo.Ensemble(n_neurons=3000, dimensions=node_pool.size_out,\n",
    "                          neuron_type=nengo.LIFRate(), seed=seed)\n",
    "\n",
    "    start = 0\n",
    "    for r in rw:\n",
    "        nengo.Connection(r.state, pool[start:start+r.state.size_out])\n",
    "        start += r.state.size_out\n",
    "\n",
    "\n",
    "\n",
    "    stim = nengo.Node(nengo.processes.PresentInput(test_aim, presentation_time=1.0/30))\n",
    "    assert stim.size_out == D\n",
    "    for i in range(D):\n",
    "        nengo.Connection(stim[i], rw[i].input, synapse=None)\n",
    "\n",
    "    p_stim = nengo.Probe(stim)\n",
    "\n",
    "    result = nengo.Node(None, size_in=1)\n",
    "    nengo.Connection(pool.neurons, result, transform=dec.T, synapse=None)\n",
    "\n",
    "    p_aim_result_sample = nengo.Probe(result, sample_every=0.1)\n",
    "\n",
    "\n",
    "aim_test_sim = nengo.Simulator(aim_test_net)\n",
    "aim_test_sim.run(T_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = aim_test_sim.data[p_aim_result_sample]\n",
    "classify = np.isclose(v, 0, atol=0.5)\n",
    "score_aim = np.mean(classify)\n",
    "\n",
    "classify_score[2]=score_aim\n",
    "    \n",
    "plt.plot(classify)\n",
    "plt.plot(v)\n",
    "plt.title('testing classification accuracy: %1.2f%%' % (score_aim*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(v, label='aimless testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aim_timestamps2 = aim_timestamps[0::3]\n",
    "\n",
    "output_aim = {}\n",
    "for i in range(len(v)):\n",
    "    output_aim[i]={\"time\":aim_timestamps[i], \"out_aim\":v[i]}\n",
    "\n",
    "for j in range(len(output_aim)):        \n",
    "    key_j = 'output_aim{}'.format(\"%04d\" % j)  \n",
    "    output_aim[key_j] = output_aim.pop(j) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = dict(islice(enumerate(v), None, None, 100)) \n",
    "accuracy_train={}\n",
    "for  in range(len(accuracy)):\n",
    "    accuracy_train[i]=accuracy[i*100]\n",
    "    \n",
    "\n",
    "\n",
    "for j in range(len(accuracy_train)):        \n",
    "    key_j = 'accuracy_train{}'.format(\"%04d\" % j)  \n",
    "    accuracy_train[key_j] = accuracy_train.pop(j)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
